# Chapter-1 Time Complexity
# 第1章 时间复杂度

--------

#### 简介

狭义的说，算法是利用计算机编程来解决数学问题的方法。对于具有确定数学模型的问题，将问题参数输入固定算法中，就可以得到该问题的解。简单的问题比如求两整数之和，这个问题的输入参数是两个整数$$ a $$和$$ b $$，解是整数$$ c $$，其中$$ c = a + b $$。复杂的问题比如求网络流的最大流，输入参数是一个网络流$$ <G, E> $$，解是该网络流的最大流$$ F_{max} $$。

时间复杂度是衡量算法性能的度量。如果把算法比作数学中的函数，那么时间复杂度就是运行该函数所消耗的时间、空间（内存）。一般将简单的数学计算、读写变量看作基本操作，其消耗的时间看作基本时间单位。基本操作只是一种大致认知，并不是死板的规定。比如在计算两个32位整数相乘问题上，考虑下面两种算法：

$$ (1) $$ 累加法模拟乘法：对于整数$$ a $$和$$ b $$，需要重复$$ a $$个$$ b $$累加求和，或$$ b $$个$$ a $$累加求和，在这个算法中把一次相加看作一个基本操作，那么其所需时间至多为$$ max(a, b) $$个时间单位；

$$ (2) $$ [Booth’s Multiplication Algorithm](https://www.google.com/search?q=Booth%E2%80%99s+Multiplication+Algorithm)：利用位操作计算两整数相乘，CPU在字节上的操作速度极快。假设$$ a = b = 10000 $$，那么第$$ (1) $$种算法需要$$ 10000 $$次累加操作，而该算法只需要$$ 5^2 = 25 $$次位操作（而且CPU的位操作速度极快）；

在上面两种算法中，抽象的认为相加是第$$ (1) $$个算法中的基本操作，位操作是第$$ (2) $$个算法中的基本操作。虽然实际的x86或amd64架构CPU上两整数和位操作的性能相差甚远，但在算法中都抽象的认为它们都是基本操作，忽略其细节的差别。我们更关注第$$ (2) $$个算法通过利用整数$$ a = b = 10000 $$的比特位为$$ 5 $$，远小于整数本身$$ 10000 $$这个值，将运算次数从$$ 10000 $$次降低到了$$ 5^2 $$次。

#### 渐进记号

不同问题的输入规模是不一样的，求两整数之和的问题规模是两个整数，即$$ 2 $$；求拥有$$ n $$个节点的网络流的最大流的问题规模则是$$ n $$。不同算法消耗的时间、空间也不一样，常用渐进记号$$ T $$表示一个问题的规模，比如$$ T(1) $$表示问题规模是常数的，$$ T(n) $$表示问题规模是线性的。用渐进记号$$ O $$来描述算法的时间复杂度或空间复杂度。常见的时间复杂度有：

$$ (1) $$ 常数时间：$$ O(1) $$，不论问题规模，算法都能在一个固定时间内解决问题，这里的$$ 1 $$并非特指1次操作，而是指固定数量的操作。比如上文中的两整数相加；

$$ (2) $$ 对数时间：$$ O(log_2 n) $$、$$ O(n \cdot log_2 n)，对于数据规模为$$ n $$的问题，可以在对数时间内解决。比如[二分搜索（Binary Search）](https://linrongbin16.gitbook.io/gitbook-way-to-algorithm/search/binarysearch)；

$$ (3) $$ 二次方时间：$$ O(n^2) $$，对于数据规模为$$ n $$的问题，需要在次方级别的时间解决。比如图论中遍历一个拥有$$ n $$个节点完全图的所有边，需要嵌套的内外两层循环来遍历图中的所有节点，外层遍历图中的每个节点，内层对于每个节点又需要遍历图中的其他所有节点；

$$ (4) $$ 三次方时间$$ O(n^3) $$、阶乘时间$$ O(n!) $$等等；

算法复杂度的关键在于计算模型所消耗的操作数量，随着问题规模增长的膨胀程度。当问题规模$$ n $$足够大时：

$$
O(n^3) \gt O(n^2) \gt O(n \cdot log_2 n) \gt O(n) \gt O(log_2 n) \gt O(1)
$$

#### 复杂度推导

判定一个算法的时间复杂度或空间复杂度需要一定的推导过程（非常熟悉的也可以一眼看出来）。
